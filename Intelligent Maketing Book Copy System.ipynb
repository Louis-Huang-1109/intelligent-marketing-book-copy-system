{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b8d412-2746-4730-a20b-cf910107bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (2.137.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (2.32.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai jieba_zh_TW pandas opencc-python-reimplemented cnsenti xgboost langchain-community openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5a36d1-1782-4562-8014-cce9895d4be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.7.3\n",
      "  Downloading scipy-1.7.3-cp310-cp310-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting gensim==3.8.1\n",
      "  Downloading gensim-3.8.1.tar.gz (23.4 MB)\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/23.4 MB 217.9 kB/s eta 0:01:48\n",
      "     --------------------------------------- 0.0/23.4 MB 217.9 kB/s eta 0:01:48\n",
      "     --------------------------------------- 0.0/23.4 MB 163.4 kB/s eta 0:02:23\n",
      "     --------------------------------------- 0.1/23.4 MB 286.7 kB/s eta 0:01:22\n",
      "     --------------------------------------- 0.1/23.4 MB 344.8 kB/s eta 0:01:08\n",
      "     --------------------------------------- 0.1/23.4 MB 327.4 kB/s eta 0:01:12\n",
      "     --------------------------------------- 0.2/23.4 MB 419.0 kB/s eta 0:00:56\n",
      "     --------------------------------------- 0.2/23.4 MB 461.0 kB/s eta 0:00:51\n",
      "     --------------------------------------- 0.2/23.4 MB 464.5 kB/s eta 0:00:50\n",
      "      -------------------------------------- 0.3/23.4 MB 561.6 kB/s eta 0:00:42\n",
      "      -------------------------------------- 0.4/23.4 MB 618.4 kB/s eta 0:00:38\n",
      "      -------------------------------------- 0.4/23.4 MB 688.1 kB/s eta 0:00:34\n",
      "      -------------------------------------- 0.5/23.4 MB 761.9 kB/s eta 0:00:30\n",
      "      -------------------------------------- 0.6/23.4 MB 788.8 kB/s eta 0:00:29\n",
      "     - ------------------------------------- 0.7/23.4 MB 882.3 kB/s eta 0:00:26\n",
      "     - -------------------------------------- 0.9/23.4 MB 1.1 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 1.0/23.4 MB 1.2 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 1.2/23.4 MB 1.3 MB/s eta 0:00:18\n",
      "     -- ------------------------------------- 1.3/23.4 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.3/23.4 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.3/23.4 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.3/23.4 MB 1.3 MB/s eta 0:00:17\n",
      "     -- ------------------------------------- 1.4/23.4 MB 1.2 MB/s eta 0:00:18\n",
      "     ---- ----------------------------------- 2.6/23.4 MB 2.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 2.6/23.4 MB 2.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 2.9/23.4 MB 2.3 MB/s eta 0:00:10\n",
      "     ----- ---------------------------------- 3.4/23.4 MB 2.5 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 3.5/23.4 MB 2.6 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 3.6/23.4 MB 2.5 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 3.7/23.4 MB 2.6 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 3.8/23.4 MB 2.5 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 4.2/23.4 MB 2.7 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 4.4/23.4 MB 2.7 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 4.6/23.4 MB 2.8 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 4.6/23.4 MB 2.8 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 4.8/23.4 MB 2.7 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 5.1/23.4 MB 2.8 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 5.3/23.4 MB 2.8 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 5.5/23.4 MB 2.9 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 5.6/23.4 MB 2.9 MB/s eta 0:00:07\n",
      "     --------- ------------------------------ 5.7/23.4 MB 2.9 MB/s eta 0:00:07\n",
      "     ---------- ----------------------------- 6.0/23.4 MB 2.9 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 6.3/23.4 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 6.6/23.4 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 6.7/23.4 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 6.9/23.4 MB 3.1 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 7.2/23.4 MB 3.2 MB/s eta 0:00:06\n",
      "     ------------ --------------------------- 7.4/23.4 MB 3.2 MB/s eta 0:00:06\n",
      "     ------------- -------------------------- 7.7/23.4 MB 3.2 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 8.0/23.4 MB 3.3 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 8.3/23.4 MB 3.4 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 8.5/23.4 MB 3.4 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 8.5/23.4 MB 3.3 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 8.7/23.4 MB 3.4 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 9.2/23.4 MB 3.4 MB/s eta 0:00:05\n",
      "     ---------------- ----------------------- 9.5/23.4 MB 3.5 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 9.7/23.4 MB 3.5 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 9.9/23.4 MB 3.5 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 10.2/23.4 MB 3.6 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 10.6/23.4 MB 4.4 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 10.8/23.4 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 11.1/23.4 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 11.1/23.4 MB 4.7 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.3/23.4 MB 4.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 11.6/23.4 MB 5.1 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 11.9/23.4 MB 5.2 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 12.2/23.4 MB 5.0 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 12.5/23.4 MB 4.9 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 12.6/23.4 MB 4.9 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 12.8/23.4 MB 4.7 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 13.1/23.4 MB 4.8 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 13.5/23.4 MB 4.8 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 13.7/23.4 MB 4.8 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 13.9/23.4 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.1/23.4 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.3/23.4 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 14.8/23.4 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.0/23.4 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.1/23.4 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.1/23.4 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.1/23.4 MB 5.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.3/23.4 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.6/23.4 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 15.9/23.4 MB 5.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.2/23.4 MB 5.0 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.5/23.4 MB 5.0 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.5/23.4 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.7/23.4 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 17.1/23.4 MB 5.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 17.5/23.4 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 17.7/23.4 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 18.0/23.4 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 18.2/23.4 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 18.3/23.4 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 18.6/23.4 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.0/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.4/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.6/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 19.9/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.2/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 20.5/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 20.8/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.1/23.4 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.3/23.4 MB 5.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.6/23.4 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.0/23.4 MB 5.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.2/23.4 MB 5.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.4/23.4 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  22.8/23.4 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.2/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.4/23.4 MB 5.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numpy<1.23.0,>=1.16.5 (from scipy==1.7.3)\n",
      "  Downloading numpy-1.22.4-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from gensim==3.8.1) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from gensim==3.8.1) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hhfeng\\anaconda3\\envs\\bs-v2\\lib\\site-packages (from smart_open>=1.8.1->gensim==3.8.1) (1.16.0)\n",
      "Downloading scipy-1.7.3-cp310-cp310-win_amd64.whl (34.3 MB)\n",
      "   ---------------------------------------- 0.0/34.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/34.3 MB 8.7 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.8/34.3 MB 8.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.1/34.3 MB 8.8 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.4/34.3 MB 7.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.6/34.3 MB 7.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.8/34.3 MB 7.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.2/34.3 MB 6.9 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.6/34.3 MB 7.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.9/34.3 MB 7.0 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.2/34.3 MB 6.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.6/34.3 MB 6.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.0/34.3 MB 7.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.2/34.3 MB 6.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 4.5/34.3 MB 7.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 4.8/34.3 MB 7.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.1/34.3 MB 7.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.5/34.3 MB 7.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 5.9/34.3 MB 7.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.2/34.3 MB 7.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.4/34.3 MB 7.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 6.7/34.3 MB 6.9 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 7.1/34.3 MB 6.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 7.3/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 7.7/34.3 MB 6.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 7.9/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 8.3/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 8.5/34.3 MB 6.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 8.7/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 9.1/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 9.6/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 9.8/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 10.0/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 10.4/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 10.7/34.3 MB 6.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 11.2/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 11.4/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 11.7/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 12.0/34.3 MB 6.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 12.4/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 12.8/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 13.1/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 13.3/34.3 MB 6.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 13.7/34.3 MB 6.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 14.1/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 14.4/34.3 MB 6.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 14.7/34.3 MB 6.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 15.1/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 15.4/34.3 MB 6.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 15.5/34.3 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 15.9/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 16.4/34.3 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 16.7/34.3 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 16.9/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 17.3/34.3 MB 6.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 17.5/34.3 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 17.8/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 18.1/34.3 MB 6.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 18.7/34.3 MB 6.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 18.9/34.3 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 19.2/34.3 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 19.5/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 19.8/34.3 MB 6.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 20.3/34.3 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 20.4/34.3 MB 6.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 20.8/34.3 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 20.9/34.3 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 21.1/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 21.5/34.3 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 21.9/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 22.2/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 22.5/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 22.8/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 23.1/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 23.6/34.3 MB 6.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 23.9/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 24.1/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 24.3/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 24.3/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 24.3/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 24.3/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 25.8/34.3 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 26.1/34.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 26.2/34.3 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 26.5/34.3 MB 6.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 26.7/34.3 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 27.0/34.3 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 27.2/34.3 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 27.5/34.3 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 27.7/34.3 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 27.9/34.3 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 28.2/34.3 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 28.5/34.3 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 28.7/34.3 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 28.8/34.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 29.2/34.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 29.5/34.3 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 29.7/34.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 29.9/34.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 30.2/34.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 30.5/34.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 30.6/34.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 30.9/34.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 31.2/34.3 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 31.6/34.3 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 31.7/34.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 31.8/34.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 32.1/34.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 32.5/34.3 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 32.8/34.3 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 32.9/34.3 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 33.3/34.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  33.5/34.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  33.8/34.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.0/34.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.1/34.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.3/34.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  34.3/34.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 34.3/34.3 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.22.4-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "   ---------------------------------------- 0.0/14.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/14.7 MB 6.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/14.7 MB 6.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.0/14.7 MB 7.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/14.7 MB 6.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/14.7 MB 6.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/14.7 MB 6.5 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/14.7 MB 4.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.7/14.7 MB 4.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.0/14.7 MB 4.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.3/14.7 MB 5.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.5/14.7 MB 5.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.8/14.7 MB 5.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.2/14.7 MB 5.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.5/14.7 MB 5.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.7/14.7 MB 5.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.9/14.7 MB 5.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.3/14.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.6/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.8/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.7 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.2/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.4/14.7 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.7/14.7 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.2/14.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.4/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.6/14.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.9/14.7 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.2/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.5/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.6/14.7 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.0/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.4/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.5/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.8/14.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.6/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.8/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.1/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.3/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.7/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.9/14.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.1/14.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.4/14.7 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.9/14.7 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.2/14.7 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.7 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.4/14.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.8/14.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.2/14.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.5/14.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.0/14.7 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.7/14.7 MB 5.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-3.8.1-cp310-cp310-win_amd64.whl size=23720071 sha256=9e61b8d504e1063a663d9aa40a133b41602e6d243e8f1faf0b7d7571a7d2d3d7\n",
      "  Stored in directory: c:\\users\\hhfeng\\appdata\\local\\pip\\cache\\wheels\\92\\23\\5d\\b5ce54b3760acfebee170a8fe4d91cb303fafbefd8f93f3723\n",
      "Successfully built gensim\n",
      "Installing collected packages: numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed gensim-3.8.1 numpy-1.22.4 scipy-1.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.7.3 gensim==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da38390-50ce-4e49-b479-622c00f28810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.22.4\n",
      "  Using cached numpy-1.22.4-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Using cached numpy-1.22.4-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.22.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "matplotlib 3.9.1 requires numpy>=1.23, but you have numpy 1.22.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.22.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7218b451-454e-447a-9223-54de92ebb593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hhfeng\\anaconda3\\envs\\BS-v2\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import jieba_zh_TW\n",
    "import jieba_zh_TW.posseg as pseg\n",
    "import re\n",
    "import pandas as pd\n",
    "import opencc\n",
    "from cnsenti import Emotion\n",
    "import pickle\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def sent_seg(paragraph):\n",
    "    sents = re.findall(u'[^！？。\\.\\！\\？\\…]+[！？。\\.\\！\\？\\…]?', paragraph, flags=re.U)\n",
    "    return sents\n",
    "\n",
    "def BS_prediction(intro):\n",
    "    data_path = \"C:/Users/hhfeng/Desktop/智慧文案輔助系統/BS Level Prediction/\"\n",
    "    cc_ts = opencc.OpenCC('tw2s')\n",
    "    emotion = Emotion()\n",
    "    \n",
    "    df = pd.read_csv(data_path+\"Keywords_Features.csv\", encoding=\"utf-8\")\n",
    "    kws = list(df[\"Keywords_Features\"])\n",
    "    \n",
    "    ws_results = jieba_zh_TW.cut(intro)\n",
    "    clean_ws_results = []\n",
    "    single_alph = list('abcdefghijklmnopqrstuvwxyz')\n",
    "    single_u_alph = list('abcdefghijklmnopqrstuvwxyz'.upper())\n",
    "    al_single_alph = list('ａｂｃｄｅｆｇｈｉｊｋｌｍｎｏｐｑｒｓｔｕｖｗｘｙｚ')\n",
    "    al_single_u_alph = list('ＡＢＣＤＥＦＧＨＩＪＫＬＭＮＯＰＱＲＳＴＵＶＷＸＹＺ')\n",
    "    al_punc = list('~～!！（）()｛｝：:＂\"＜＞<>？?’［］[]【】「」『』〔〕，,。.、·‧﹒．﹐﹑；:;﹔＋+＝=＆&《 》〈 〉◦•﹞﹝﹡{}')\n",
    "    years = [str(y) for y in range(1700, 2101)]\n",
    "    m_years = [str(y) for y in range(50, 131)]\n",
    "\n",
    "    model = pickle.load(open(data_path+\"(jieba_notin)xgb_067prob_kw2v_ttr_pos_mls_senti.pickle.dat\", \"rb\"))\n",
    "    w2v_model = Word2Vec.load(data_path+\"(jieba_notin)kingstone_word2vec_d300_unibitri_mincount2.model\")\n",
    "\n",
    "\n",
    "    for w in ws_results:\n",
    "        if w == \"hellip\" or w == \"mdash\" or w == \"\\n\" or w == \"hellip;\" or w == \"mdash;\" or w == \"bull\" or w == \"&\" or w == \"&&\" or w == \"&&&\" or w == \"rarr\" or w == \"／\" or w == \"middot\" or w == \"】\" or w == \"【\" or w == \"middot\" or w == \"․\" or w == \"∕\" or w == \"color\" or w == \"rgb\" or w == \"Arial\" or w == \"height\" or w == \"size\" or w == \"family\" or w == \"明體\" or w == \"新細\" or w == 'sans' or w == 'Helvetica' or w == 'Verdana' or w == 'serif' or w == '17px' or w == 'small' or w == 'border' or w == 'sizing' or w == ';' or w == \"：\" or w == \"\\u3000\" or w == \"．\"or w == '\\uf050' or w == '&&&&' or w == '&&&&&' or w == '&&&&&&' or w == '&&&&&&&' or w == '&&&&&&&&' or w == '&#' or w == 'ｍ' or w == 'ｐ' or w == '&&&&&&&&&' or w == '\\x84' or w == 'pstyle' or w == 'margin' or w == 'divstyle' or w == 'fontsize' or w == 'align' or w == 'yellownonerepeatscroll0':\n",
    "            pass\n",
    "        elif w in single_alph or w in al_single_alph or w in single_u_alph or w in al_single_u_alph or w in years or w in al_punc or w in m_years:\n",
    "            pass\n",
    "        elif re.search(\"uf\", str(w.encode('unicode_escape'))) or re.search('px', w) or re.search('&', w) or re.search(\"page\", w):\n",
    "            pass\n",
    "        elif w == '':\n",
    "            pass\n",
    "        else:\n",
    "            clean_ws_results.append(w)\n",
    "    \n",
    "    intro_segs_uni = []\n",
    "    intro_segs_bi = []\n",
    "    intro_segs_tri = []\n",
    "    \n",
    "    intro_segs_uni.append(\"/\".join(clean_ws_results))\n",
    "    \n",
    "    tuple_bi_ = list(zip(clean_ws_results, clean_ws_results[1:]))\n",
    "    bi_ = []\n",
    "    for t in tuple_bi_:\n",
    "        b = t[0]+\"_\"+t[1]\n",
    "        bi_.append(b)\n",
    "    intro_segs_bi.append(\"/\".join(bi_))\n",
    "    \n",
    "    tuple_tri_ = list(zip(clean_ws_results, clean_ws_results[1:], clean_ws_results[2:]))\n",
    "    tri_ = []\n",
    "    for t in tuple_tri_:\n",
    "        tt = t[0]+\"_\"+t[1]+\"_\"+t[2]\n",
    "        tri_.append(tt)\n",
    "    intro_segs_tri.append(\"/\".join(tri_))\n",
    "    \n",
    "    kw_result_df = pd.DataFrame()\n",
    "    uni_words = \"\".join(intro_segs_uni).split(\"/\")\n",
    "    bi_words = \"\".join(intro_segs_bi).split(\"/\")\n",
    "    tri_words = \"\".join(intro_segs_tri).split(\"/\")\n",
    "    \n",
    "    mls = round(len(uni_words)/len(sent_seg(intro)), 3)\n",
    "    T = len(list(set(uni_words)))\n",
    "    ttr = round(len(list(set(uni_words)))/len(intro_segs_uni), 3)\n",
    "    \n",
    "    kw_result_df[\"Mean_Length_of_Sentence\"] = [float(mls)]\n",
    "    kw_result_df[\"Type\"] = [float(T)]\n",
    "    kw_result_df[\"TTR\"] = [float(ttr)]\n",
    "    \n",
    "    intro_pos = []\n",
    "    \n",
    "    word_pos = pseg.cut(\"\".join(\"\".join(intro_segs_uni).split(\"/\")))\n",
    "    for word, pos in word_pos:\n",
    "        intro_pos.append(pos)\n",
    "    \n",
    "    universal_ps = []\n",
    "    content_words = []\n",
    "    verb_ws = []\n",
    "    noun_ws = []\n",
    "    adj_ws = []\n",
    "    adv_ws = []\n",
    "    conj_ws = []\n",
    "    pron_ws = []\n",
    "    adp_ws = []\n",
    "    prt_ws = []\n",
    "    num_ws = []\n",
    "    \n",
    "    for pst in intro_pos:\n",
    "        if pst == 'd' or pst == \"dg\" or pst == \"h\" or pst == \"t\" or pst == \"zg\" or pst == 'z':\n",
    "            universal_ps.append(\"ADV\")\n",
    "            content_words.append(\"ADV\")\n",
    "            adv_ws.append(\"ADV\")\n",
    "        elif pst == 'a' or pst == 'ad' or pst == \"b\" or pst == \"an\" or pst == \"ag\" or pst == \"i\" or pst == 'l':\n",
    "            universal_ps.append(\"ADJ\")\n",
    "            content_words.append(\"ADJ\")\n",
    "            adj_ws.append(\"ADJ\")\n",
    "        elif pst == 'j' or pst == 'mg' or pst == 'n' or pst == 'ng' or pst == 'nr' or pst == 'nrfg' or pst == 'nrt' or pst == 'ns' or pst == 'nt' or pst == 'nz' or pst == 's' or pst == 'tg' or pst == 't':\n",
    "            universal_ps.append(\"NOUN\")\n",
    "            content_words.append(\"NOUN\")\n",
    "            noun_ws.append(\"NOUN\")\n",
    "        elif pst == \"df\" or pst == 'f' or pst == 'v' or pst == 'vg' or pst == 'vd' or pst == 'vi' or pst == 'vn' or pst == 'vq':\n",
    "            universal_ps.append(\"VERB\")\n",
    "            content_words.append(\"VERB\")\n",
    "            verb_ws.append(\"VERB\")\n",
    "        elif pst == 'c':\n",
    "            universal_ps.append(\"CONJ\")\n",
    "            conj_ws.append(\"CONJ\")\n",
    "        elif pst == 'k' or pst == 'mq' or pst == 'r' or pst == 'rg' or pst == 'rr' or pst == 'rz':\n",
    "            universal_ps.append(\"PRON\")\n",
    "            pron_ws.append(\"PRON\")\n",
    "        elif pst == 'm' or pst == 'q':\n",
    "            universal_ps.append(\"NUM\")\n",
    "            num_ws.append(\"NUM\")\n",
    "        elif pst == 'u' or pst == 'ud' or pst == 'uj' or pst == 'uv' or pst == 'ug' or pst == 'ul' or pst == 'uz' or pst == 'y':\n",
    "            universal_ps.append(\"PRT\")\n",
    "            prt_ws.append(\"PRT\")\n",
    "        elif pst == 'p':\n",
    "            universal_ps.append(\"ADP\")\n",
    "            adp_ws.append(\"ADP\")\n",
    "    \n",
    "    pos_types = [\"ADV\", \"ADJ\", \"NOUN\", \"VERB\", \"CONJ\", \"PRON\", \"NUM\", \"PRT\", \"ADP\"]\n",
    "    for p in pos_types:\n",
    "        kw_result_df[p+\"_Ratio\"] = [float(round(universal_ps.count(p)/len(universal_ps), 3))]\n",
    "    \n",
    "    kw_result_df[\"Lexical_Density\"] = [round(len(content_words)/len(universal_ps), 3)]\n",
    "    if len(content_words) == 0:\n",
    "        kw_result_df[\"Lexical_Variation\"] = [0]\n",
    "        kw_result_df[\"Noun_Variation\"] = [0]\n",
    "        kw_result_df[\"Adjective_Variation\"] = [0]\n",
    "        kw_result_df[\"Adverb_Variation\"] = [0]\n",
    "        kw_result_df[\"Modifier_Variation\"] = [0]\n",
    "    else: \n",
    "        kw_result_df[\"Lexical_Variation\"] = [round(len(list(set(content_words)))/len(content_words), 3)]\n",
    "        kw_result_df[\"Noun_Variation\"] = [round(len(list(set(noun_ws)))/len(content_words), 3)]\n",
    "        kw_result_df[\"Adjective_Variation\"] = [round(len(list(set(adj_ws)))/len(content_words), 3)]\n",
    "        kw_result_df[\"Adverb_Variation\"] = [round(len(list(set(adv_ws)))/len(content_words), 3)]\n",
    "        kw_result_df[\"Modifier_Variation\"] = [round((len(list(set(adv_ws)))+len(list(set(adj_ws))))/len(content_words), 3)]\n",
    "    \n",
    "    if len(verb_ws) == 0: \n",
    "        kw_result_df[\"Verb_VariationI\"] = [0]\n",
    "    else: \n",
    "         kw_result_df[\"Verb_VariationI\"] = [round(len(list(set(verb_ws)))/len(verb_ws), 3)]\n",
    "    \n",
    "    if len(verb_ws) == 0 or len(content_words) == 0: \n",
    "        kw_result_df[\"Verb_VariationII\"] = [0]\n",
    "    else: \n",
    "        kw_result_df[\"Verb_VariationII\"] = [round(len(list(set(verb_ws)))/len(content_words), 3)]\n",
    "    \n",
    "    cc_ts = opencc.OpenCC('tw2s')\n",
    "    \n",
    "    words = [cc_ts.convert(w) for w in intro_segs_uni]\n",
    "    result = emotion.emotion_count(\" \".join(words))\n",
    "    \n",
    "    kw_result_df[\"Preference\"] = [round(result.get(\"好\")/len(words), 3)]\n",
    "    kw_result_df[\"Happiness\"] = [round(result.get(\"乐\")/len(words), 3)]\n",
    "    kw_result_df[\"Sadness\"] = [round(result.get(\"哀\")/len(words), 3)]\n",
    "    kw_result_df[\"Anger\"] = [round(result.get(\"怒\")/len(words), 3)]\n",
    "    kw_result_df[\"Afraid\"] = [round(result.get(\"惧\")/len(words), 3)]\n",
    "    kw_result_df[\"Hate\"] = [round(result.get(\"恶\")/len(words), 3)]\n",
    "    kw_result_df[\"Suprise\"] = [round(result.get(\"惊\")/len(words), 3)]\n",
    "\n",
    "    normal_kws = []\n",
    "    bs_kws = []\n",
    "    tea_kws = []\n",
    "    normal_kws_sims = []\n",
    "    bs_kws_sims = []\n",
    "    tea_kws_sims = []\n",
    "\n",
    "    for t in kws:\n",
    "        if re.search(\"_\", t):\n",
    "            if len(t.split(\"_\")) == 2:\n",
    "                words = \"\".join(intro_segs_bi).split(\"/\")\n",
    "                similarities = []\n",
    "                sim_ws = []\n",
    "                for w in words:\n",
    "                    try:\n",
    "                        sim = w2v_model.wv.similarity(t, w)\n",
    "                        similarities.append(sim)\n",
    "                        sim_ws.append(w)\n",
    "                    except:\n",
    "                        pass\n",
    "                if len(similarities) > 0:\n",
    "                    kw_result_df[t] = [max(similarities)]\n",
    "                    k_index = similarities.index(max(similarities))\n",
    "                else:\n",
    "                    kw_result_df[t] = [0]\n",
    "            elif len(t.split(\"_\")) == 3:\n",
    "                words = \"\".join(intro_segs_tri).split(\"/\")\n",
    "                similarities = []\n",
    "                sim_ws = []\n",
    "                for w in words:\n",
    "                    try:\n",
    "                        sim = w2v_model.wv.similarity(t, w)\n",
    "                        similarities.append(sim)\n",
    "                        sim_ws.append(w)\n",
    "                    except:\n",
    "                        pass\n",
    "                if len(similarities) > 0: \n",
    "                    kw_result_df[t] = [max(similarities)]\n",
    "                    k_index = similarities.index(max(similarities))\n",
    "                else:\n",
    "                    kw_result_df[t] = [0]\n",
    "        else:\n",
    "            words = \"\".join(intro_segs_uni).split(\"/\")\n",
    "            similarities = []\n",
    "            sim_ws = []\n",
    "            for w in words:\n",
    "                try:\n",
    "                    sim = w2v_model.wv.similarity(t, w)\n",
    "                    similarities.append(sim)\n",
    "                    sim_ws.append(w)\n",
    "                except:\n",
    "                    pass\n",
    "            if len(similarities) > 0: \n",
    "                kw_result_df[t] = [max(similarities)]\n",
    "                k_index = similarities.index(max(similarities))\n",
    "            else:\n",
    "                kw_result_df[t] = [0]\n",
    "\n",
    "    features = model.feature_names\n",
    "    kw_result_df = kw_result_df.reindex(columns=features)\n",
    "    preds = np.zeros((kw_result_df.shape[0], 3))\n",
    "    preds = model.predict(xgb.DMatrix(kw_result_df))\n",
    "    \n",
    "    ptf_percentage = []\n",
    "    for pft in preds:\n",
    "        p_percentage = []\n",
    "        for p in pft:\n",
    "            p_percentage.append(str((Decimal(str(p))*Decimal(str(100))).quantize(Decimal('.00'), ROUND_HALF_UP))+\"%\")\n",
    "        ptf_percentage.append(p_percentage)\n",
    "\n",
    "    out_df = pd.DataFrame(ptf_percentage)\n",
    "    out_df.columns = ['一般', '熱銷', '歷久彌新']\n",
    "    return out_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7efaf79-d192-401a-9a41-76cc12f5411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "api_key = \"YOUR_GEMINI_API_KEY\"\n",
    "genai.configure(api_key = api_key)\n",
    "\n",
    "gemini = genai.GenerativeModel('gemini-pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5589b8cd-3197-4aa5-abb7-fe2fcaf55647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from openai import OpenAI\n",
    "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "client = OpenAI()\n",
    "llm = Ollama(model=\"znbang/breeze:7b-instruct-v0.1-Q8_0\")\n",
    "copy = {}\n",
    "book = open(\"book.txt\", encoding=\"UTF-8\").read()\n",
    "query = f\"\"\"你現在是一個專業的文案寫作專家，請寫下你經由思考過後，精心設計的文案。請根據使用者的指令跟需求給予相應的幫助。請根據文步的定義及內容，撰寫高品質，有吸引力的該文步內容。無需給予其他不相關的說明跟敘述。文本書籍：{book}\"\"\"\n",
    "\n",
    "moves_def = [\"行銷語\",\"內容摘要\",\"本書特色\",\"名人推薦\",\"特別收錄\"]\n",
    "experts = {\"行銷語\":{}, \"內容摘要\":{}, \"本書特色\":{},\"名人推薦\":{}, \"特別收錄\":{}}\n",
    "\n",
    "def llm_eval(a,b,c):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"你是一個只會說繁體中文的助手，請根據使用者的指令跟需求給予相應的幫助。請根據文步的定義及內容，撰寫高品質，有吸引力的該文步內容。\"},\n",
    "        {\"role\": \"user\", \"content\":f\"\"\"下列有三個專家的書本行銷文案，請幫我各自依照不同的標準給它分數，以阿拉伯數字1-10分，不用給我其他無關的敘述跟說明。\n",
    "        參考標準如下：[1.清晰性和相關性:, 2.吸引力和說服力, 3.行動呼籲]。\n",
    "        清晰性與相關性定義: 指書籍銷售文案如何清楚且相關地傳達書籍的本質和吸引力。清晰和相關的銷售文案可以幫助潛在讀者迅速且精確地理解書籍的內容及其重要性。\n",
    "        吸引力與說服力定義: 此方面專注於書籍銷售文案的吸引力和說服力。它涉及吸引讀者的興趣並說服他們書籍的價值，從而影響他們的購買決定。\n",
    "        行動呼籲定義: 書籍銷售文案中的行動呼籲是直接請求或建議，鼓勵讀者立即採取行動，例如購買書籍或進一步了解。有效的行動呼籲對於將興趣轉化為實際銷售至關重要。\n",
    "        生成格式如下:\n",
    "        [專家A:清晰性和相關性:分數,參與度和說服力:分數,行動呼籲:分數, 文步文本],\n",
    "        [專家B:清晰性和相關性:分數,參與度和說服力:分數,行動呼籲:分數, 文步文本], \n",
    "        [專家C:清晰性和相關性:分數,參與度和說服力:分數,行動呼籲:分數, 文步文本]。{a},{b},{c}\"\"\"}\n",
    "      ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def decode_unicode(unicode_string):\n",
    "    # Decode the unicode string to readable characters\n",
    "    decoded_string = unicode_string.encode().decode('unicode_escape')\n",
    "    return decoded_string\n",
    "    \n",
    "def generate_text(prompt):\n",
    "    res = gemini.generate_content(prompt)\n",
    "\n",
    "    return res\n",
    "\n",
    "def best_BS_decision(move):\n",
    "    if move == \"行銷語\":\n",
    "        res = m1_res\n",
    "    elif move == \"內容摘要\":\n",
    "        res = m2_res\n",
    "    elif move == \"本書特色\":\n",
    "        res = m3_res\n",
    "    elif move == \"名人推薦\":\n",
    "        res = m4_res\n",
    "    elif move == \"特別收錄\":\n",
    "        res = m5_res\n",
    "\n",
    "    expert_A_avg = re.findall(\"專家A:.*(\\d+).*(\\d+).*(\\d+)\",res)[0]\n",
    "    expert_B_avg = re.findall(\"專家B:.*(\\d+).*(\\d+).*(\\d+)\",res)[0]    \n",
    "    expert_C_avg = re.findall(\"專家C:.*(\\d+).*(\\d+).*(\\d+)\",res)[0]    \n",
    "\n",
    "    expert_A_score = round(sum(int(num) for num in expert_A_avg)/3,2)\n",
    "    expert_B_score = round(sum(int(num) for num in expert_B_avg)/3,2)\n",
    "    expert_C_score = round(sum(int(num) for num in expert_C_avg)/3,2)\n",
    "    \n",
    "    expert_A_intro = decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[move][\"專家A\"]))[0])\n",
    "    expert_B_intro = decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[move][\"專家B\"]))[0])\n",
    "    expert_C_intro = decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[move][\"專家C\"]))[0])\n",
    "    \n",
    "    expert_A_BSpred = BS_prediction(expert_A_intro)\n",
    "    expert_B_BSpred = BS_prediction(expert_B_intro)\n",
    "    expert_C_BSpred = BS_prediction(expert_C_intro)\n",
    "    \n",
    "    A_pred_score = round(float(expert_A_BSpred[\"歷久彌新\"][0].strip(\"%\"))/10*1+float(expert_A_BSpred[\"熱銷\"][0].strip(\"%\"))/10*0.5, 2)\n",
    "    B_pred_score = round(float(expert_B_BSpred[\"歷久彌新\"][0].strip(\"%\"))/10*1+float(expert_B_BSpred[\"熱銷\"][0].strip(\"%\"))/10*0.5, 2)\n",
    "    C_pred_score = round(float(expert_C_BSpred[\"歷久彌新\"][0].strip(\"%\"))/10*1+float(expert_C_BSpred[\"熱銷\"][0].strip(\"%\"))/10*0.5, 2)\n",
    "    \n",
    "    A_final_score = expert_A_score+A_pred_score\n",
    "    B_final_score = expert_B_score+B_pred_score\n",
    "    C_final_score = expert_C_score+C_pred_score\n",
    "    \n",
    "    score_list = [A_final_score, B_final_score, C_final_score]\n",
    "    best_id = score_list.index(max(score_list))\n",
    "    \n",
    "    if best_id == 0:\n",
    "        return expert_A_intro\n",
    "    elif best_id == 1:\n",
    "        return expert_B_intro\n",
    "    elif best_id == 2:\n",
    "        return expert_C_intro\n",
    "        \n",
    "\n",
    "def BS_score(move):\n",
    "    if move == \"行銷語\":\n",
    "        res = m1_res\n",
    "    elif move == \"內容摘要\":\n",
    "        res = m2_res\n",
    "    elif move == \"本書特色\":\n",
    "        res = m3_res\n",
    "    elif move == \"名人推薦\":\n",
    "        res = m4_res\n",
    "    elif move == \"特別收錄\":\n",
    "        res = m5_res\n",
    "\n",
    "    expert_A_avg = re.findall(\"專家A:.*(\\d+).*(\\d+).*(\\d+)\",res)[0]\n",
    "    expert_B_avg = re.findall(\"專家B:.*(\\d+).*(\\d+).*(\\d+)\",res)[0]    \n",
    "    expert_C_avg = re.findall(\"專家C:.*(\\d+).*(\\d+).*(\\d+)\",res)[0]    \n",
    "\n",
    "    expert_A_score = round(sum(int(num) for num in expert_A_avg)/3,2)\n",
    "    expert_B_score = round(sum(int(num) for num in expert_B_avg)/3,2)\n",
    "    expert_C_score = round(sum(int(num) for num in expert_C_avg)/3,2)\n",
    "    \n",
    "    expert_A_intro = decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[move][\"專家A\"]))[0])\n",
    "    expert_B_intro = decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[move][\"專家B\"]))[0])\n",
    "    expert_C_intro = decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[move][\"專家C\"]))[0])\n",
    "    \n",
    "    expert_A_BSpred = BS_prediction(expert_A_intro)\n",
    "    expert_B_BSpred = BS_prediction(expert_B_intro)\n",
    "    expert_C_BSpred = BS_prediction(expert_C_intro)\n",
    "    \n",
    "    A_pred_score = round(float(expert_A_BSpred[\"歷久彌新\"][0].strip(\"%\"))/10*1+float(expert_A_BSpred[\"熱銷\"][0].strip(\"%\"))/10*0.5, 2)\n",
    "    B_pred_score = round(float(expert_B_BSpred[\"歷久彌新\"][0].strip(\"%\"))/10*1+float(expert_B_BSpred[\"熱銷\"][0].strip(\"%\"))/10*0.5, 2)\n",
    "    C_pred_score = round(float(expert_C_BSpred[\"歷久彌新\"][0].strip(\"%\"))/10*1+float(expert_C_BSpred[\"熱銷\"][0].strip(\"%\"))/10*0.5, 2)\n",
    "    \n",
    "    A_final_score = expert_A_score+A_pred_score\n",
    "    B_final_score = expert_B_score+B_pred_score\n",
    "    C_final_score = expert_C_score+C_pred_score\n",
    "    \n",
    "    \n",
    "    return A_final_score, B_final_score, C_final_score\n",
    "\n",
    "for move in range(5):\n",
    "    if move == 0:\n",
    "        prompt= f\"{query}, 請幫我生成 {moves_def[0]}的文步內容，行銷語目的在於吸引讀者注意及引發興趣，並使讀者在閱讀接下來的文案之前，可以快速進入該書之語境。此文步位於開頭，常搭配符號，如「★」。\"\n",
    "\n",
    "        expert_a = generate_text(prompt)\n",
    "        expert_b = generate_text(prompt)\n",
    "        expert_c = generate_text(prompt)\n",
    "\n",
    "        \n",
    "        experts[\"行銷語\"][\"專家A\"] = expert_a\n",
    "        experts[\"行銷語\"][\"專家B\"] = expert_b\n",
    "        experts[\"行銷語\"][\"專家C\"] = expert_c\n",
    "\n",
    "        ###after-eval\n",
    "        m1_res = llm_eval(expert_a, expert_b, expert_c)\n",
    "        m1_final = best_BS_decision(moves_def[0])\n",
    "        copy[\"行銷語\"] = m1_final\n",
    "\n",
    "    elif move == 1:\n",
    "        prompt = f\"{query}, 目前已生成好的文本如下：行銷術語：{copy['行銷語']}，請根據目前已生成好的文步內容，繼續思考下一個文步內容的撰寫。下一個欲生成的文步： {moves_def[1]} 。內容摘要旨在介紹整本書之重點內容摘要或背景知識，以讓讀者了解整本書所圍繞之重點。\"\n",
    "        expert_a = generate_text(prompt)\n",
    "        expert_b = generate_text(prompt)\n",
    "        expert_c = generate_text(prompt)\n",
    "        \n",
    "        experts[\"內容摘要\"][\"專家A\"] = expert_a\n",
    "        experts[\"內容摘要\"][\"專家B\"] = expert_b\n",
    "        experts[\"內容摘要\"][\"專家C\"] = expert_c\n",
    "\n",
    "        ###after-eval\n",
    "\n",
    "        m2_res = llm_eval(expert_a, expert_b, expert_c)\n",
    "\n",
    "        m2_final = best_BS_decision(moves_def[1])\n",
    "        copy[\"內容摘要\"] = m2_final\n",
    "        \n",
    "    elif move == 2:\n",
    "        prompt = f\"{query}, 目前已生成好的文本如下：行銷語：{copy['行銷語']}，內容摘要：{copy['內容摘要']}，請再根據目前已生成好的文步繼續思考下一個文步內容的撰寫。下一個欲生成的文步： {moves_def[2]}。本書特色是用於介紹該書與其他書的差異，以讓讀者了解到，藉由閱讀該書後，可以學到從類似書籍所不能習得的新知識。\"\n",
    "        \n",
    "        experts[\"本書特色\"][\"專家A\"] = generate_text(prompt)\n",
    "        experts[\"本書特色\"][\"專家B\"] = generate_text(prompt)\n",
    "        experts[\"本書特色\"][\"專家C\"] = generate_text(prompt)\n",
    "\n",
    "        ###after-eval\n",
    "\n",
    "        m3_res = llm_eval(expert_a, expert_b, expert_c)\n",
    "\n",
    "        m3_final = best_BS_decision(moves_def[2])\n",
    "        copy[\"本書特色\"] = m3_final\n",
    "        \n",
    "    elif move == 3:\n",
    "        prompt = f\"{query}, 目前已生成好的文本如下：行銷語：{copy['行銷語']}，內容摘要：{copy['內容摘要']}，本書特色：{copy['本書特色']}，請再根據目前已生成好的文步繼續思考下一個文步內容的撰寫。下一個欲生成的文步： {moves_def[3]}。名人推薦在於介紹該書得到哪些名人的推薦，包含推薦語。\"\n",
    "        \n",
    "        experts[\"名人推薦\"][\"專家A\"] = generate_text(prompt)\n",
    "        experts[\"名人推薦\"][\"專家B\"] = generate_text(prompt)\n",
    "        experts[\"名人推薦\"][\"專家C\"] = generate_text(prompt)\n",
    "        \n",
    "        ###after-eval\n",
    "        m4_res = llm_eval(expert_a, expert_b, expert_c)\n",
    "        m4_final = best_BS_decision(moves_def[3])\n",
    "        copy[\"名人推薦\"] = m4_final\n",
    "    \n",
    "    elif move == 4:\n",
    "        prompt = f\"{query}, 目前已生成好的文本如下：行銷語：{copy['行銷語']}，內容摘要：{copy['內容摘要']}，本書特色：{copy['本書特色']}，{copy['名人推薦']}，請再根據目前已生成好的文步繼續思考下一個文步內容的撰寫。下一個欲生成的文步： {moves_def[4]}。特別收錄在介紹特別隨書附贈之圖表。請統一以String形式生成。\"\n",
    "        \n",
    "        experts[\"特別收錄\"][\"專家A\"] = generate_text(prompt)\n",
    "        experts[\"特別收錄\"][\"專家B\"] = generate_text(prompt)\n",
    "        experts[\"特別收錄\"][\"專家C\"] = generate_text(prompt)\n",
    "        \n",
    "        ###after-eval\n",
    "        m5_res = llm_eval(expert_a, expert_b, expert_c)\n",
    "\n",
    "        m5_final = best_BS_decision(moves_def[4])\n",
    "\n",
    "        copy[\"特別收錄\"] = m5_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d47ac3-22cc-4ced-9f91-5b85aa827368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "★ 解開財富密碼：成為理財高手，打造財務自由之路！\n",
      "**內容摘要**\n",
      "\n",
      "踏入財務管理的世界，揭開理財致富的奧秘！\n",
      "\n",
      "本書涵蓋一系列財經知識，從個人理財的基礎，到投資策略的進階應用，為您提供全方位的財務指南。您將學習如何：\n",
      "\n",
      "* 掌握預算和儲蓄，為您的財務目標奠定基礎\n",
      "* 有效管理債務，避免陷入財務困境\n",
      "* 利用保險保障您的財務未來\n",
      "* 識別和利用稅務優惠，增加您的投資回報\n",
      "\n",
      "深入投資領域，本書將探討股票、債券、共同基金和房地產投資的方方面面，幫助您建立多元化的投資組合。此外，您還將了解風險管理的重要性，以及如何使用對沖策略和技術分析來提高您的投資績效。\n",
      "\n",
      "本書旨在為您提供實用的財務知識，讓您具備必要的技能，掌控您的財務，實現財務自由和財富增值。無論您是財務新手還是經驗豐富的投資者，這本書都能讓您受益匪淺，踏上財務成功之路。\n",
      "**本書特色**\n",
      "\n",
      "與眾不同的財經指南，助您脫穎而出：\n",
      "\n",
      "* **全面實用：**從基礎財務管理到進階投資策略，涵蓋所有重要的財經知識。\n",
      "* **深入淺出：**以清晰易懂的語言闡述複雜的概念，讓初學者也能輕鬆入門。\n",
      "* **案例豐富：**結合實際案例，幫助您將理論知識應用於現實生活中。\n",
      "* **專業觀點：**彙集業界專家的見解，提供寶貴的投資策略和財務建議。\n",
      "* **全方位指導：**從個人理財到全球經濟，為您的財務規劃提供全方位的指導。\n",
      "\n",
      "選擇本書，您不僅能獲得財經知識，更能獲得理財致富的實用技能，助您踏上財務自由之路，創造財富豐盛的人生！\n",
      "**名人推薦**\n",
      "\n",
      "「這本書是財務管理的寶典，為個人理財和投資提供全方位的指導。它將幫助您掌控您的財務，實現財務自由和財富增值。」\n",
      "\n",
      "——理財暢銷書作者 約翰·博格\n",
      "\n",
      "「對於任何想要提高財務素養和投資知識的人來說，這本書都是必不可少的讀物。它以清晰易懂的方式涵蓋了所有重要的財經概念。」\n",
      "\n",
      "——《華爾街日報》專欄作家 沃倫·巴菲特\n",
      "\n",
      "「我強烈推薦這本書給所有想要掌控自己的財務未來的人。它充滿了實用的建議和有價值的見解，將幫助您實現您的財務目標。」\n",
      "\n",
      "——投資大師 彼得·林奇\n",
      "**特別收錄**\n",
      "\n",
      "* 隨書附贈：財務規劃工作表和投資組合追蹤器，幫助您制定理財計畫和管理投資。\n",
      "* 專屬線上資源：提供額外的文章、影片和互動工具，讓您深入探索財經世界。\n"
     ]
    }
   ],
   "source": [
    "print(copy[\"行銷語\"])\n",
    "print(copy[\"內容摘要\"])\n",
    "print(copy[\"本書特色\"])\n",
    "print(copy[\"名人推薦\"])\n",
    "print(copy[\"特別收錄\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a8aa697-fd92-46f4-a302-a3075033c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**內容摘要**\n",
      "\n",
      "踏入財務管理的世界，揭開理財致富的奧秘！\n",
      "\n",
      "本書涵蓋一系列財經知識，從個人理財的基礎，到投資策略的進階應用，為您提供全方位的財務指南。您將學習如何：\n",
      "\n",
      "* 掌握預算和儲蓄，為您的財務目標奠定基礎\n",
      "* 有效管理債務，避免陷入財務困境\n",
      "* 利用保險保障您的財務未來\n",
      "* 識別和利用稅務優惠，增加您的投資回報\n",
      "\n",
      "深入投資領域，本書將探討股票、債券、共同基金和房地產投資的方方面面，幫助您建立多元化的投資組合。此外，您還將了解風險管理的重要性，以及如何使用對沖策略和技術分析來提高您的投資績效。\n",
      "\n",
      "本書旨在為您提供實用的財務知識，讓您具備必要的技能，掌控您的財務，實現財務自由和財富增值。無論您是財務新手還是經驗豐富的投資者，這本書都能讓您受益匪淺，踏上財務成功之路。**內容摘要**\n",
      "\n",
      "踏入財務管理的世界，揭開理財致富的奧秘！\n",
      "\n",
      "本書涵蓋一系列財經知識，從個人理財的基礎，到投資策略的進階應用，為您提供全方位的財務指南。您將學習如何：\n",
      "\n",
      "* 掌握預算和儲蓄，為您的財務目標奠定基礎\n",
      "* 有效管理債務，避免陷入財務困境\n",
      "* 利用保險保障您的財務未來\n",
      "* 識別和利用稅務優惠，增加您的投資回報\n",
      "\n",
      "深入投資領域，本書將探討股票、債券、共同基金和房地產投資的方方面面，幫助您建立多元化的投資組合。此外，您還將了解風險管理的重要性，以及如何使用對沖策略和技術分析來提高您的投資績效。\n",
      "\n",
      "本書旨在為您提供實用的財務知識，讓您具備必要的技能，掌控您的財務，實現財務自由和財富增值。無論您是財務新手還是經驗豐富的投資者，這本書都能讓您受益匪淺，踏上財務成功之路。**本書特色**\n",
      "\n",
      "與眾不同的財經指南，助您脫穎而出：\n",
      "\n",
      "* **全面實用：**從基礎財務管理到進階投資策略，涵蓋所有重要的財經知識。\n",
      "* **深入淺出：**以清晰易懂的語言闡述複雜的概念，讓初學者也能輕鬆入門。\n",
      "* **案例豐富：**結合實際案例，幫助您將理論知識應用於現實生活中。\n",
      "* **專業觀點：**彙集業界專家的見解，提供寶貴的投資策略和財務建議。\n",
      "* **全方位指導：**從個人理財到全球經濟，為您的財務規劃提供全方位的指導。\n",
      "\n",
      "選擇本書，您不僅能獲得財經知識，更能獲得理財致富的實用技能，助您踏上財務自由之路，創造財富豐盛的人生！**名人推薦**\n",
      "\n",
      "「這本書是財務管理的寶典，為個人理財和投資提供全方位的指導。它將幫助您掌控您的財務，實現財務自由和財富增值。」\n",
      "\n",
      "——理財暢銷書作者 約翰·博格\n",
      "\n",
      "「對於任何想要提高財務素養和投資知識的人來說，這本書都是必不可少的讀物。它以清晰易懂的方式涵蓋了所有重要的財經概念。」\n",
      "\n",
      "——《華爾街日報》專欄作家 沃倫·巴菲特\n",
      "\n",
      "「我強烈推薦這本書給所有想要掌控自己的財務未來的人。它充滿了實用的建議和有價值的見解，將幫助您實現您的財務目標。」\n",
      "\n",
      "——投資大師 彼得·林奇**特別收錄**\n",
      "\n",
      "* 隨書附贈：財務規劃工作表和投資組合追蹤器，幫助您制定理財計畫和管理投資。\n",
      "* 專屬線上資源：提供額外的文章、影片和互動工具，讓您深入探索財經世界。\n"
     ]
    }
   ],
   "source": [
    "final = copy[\"內容摘要\"] + copy[\"內容摘要\"] + copy[\"本書特色\"] + copy[\"名人推薦\"] + copy[\"特別收錄\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74cdd934-013f-48e6-a8d8-8f6a48b33dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "book_copies = pd.DataFrame({\"行銷語\":{\"專家A\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"行銷語\"][\"專家A\"]))[0]),\n",
    "                                      \"專家B\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"行銷語\"][\"專家B\"]))[0]),\n",
    "                                      \"專家C\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"行銷語\"][\"專家C\"]))[0])},\n",
    "                           \"內容摘要\":{\"專家A\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"內容摘要\"][\"專家A\"]))[0]),\n",
    "                                      \"專家B\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"內容摘要\"][\"專家B\"]))[0]),\n",
    "                                      \"專家C\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"內容摘要\"][\"專家C\"]))[0])},\n",
    "                           \"本書特色\":{\"專家A\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"本書特色\"][\"專家A\"]))[0]),\n",
    "                                       \"專家B\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"本書特色\"][\"專家B\"]))[0]),\n",
    "                                       \"專家C\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"本書特色\"][\"專家C\"]))[0])},\n",
    "                           \"名人推薦\":{\"專家A\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"名人推薦\"][\"專家A\"]))[0]),\n",
    "                                       \"專家B\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"名人推薦\"][\"專家B\"]))[0]),\n",
    "                                       \"專家C\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"名人推薦\"][\"專家C\"]))[0])},\n",
    "                           \"特別收錄\":{\"專家A\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"特別收錄\"][\"專家A\"]))[0]),\n",
    "                                       \"專家B\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"特別收錄\"][\"專家B\"]))[0]),\n",
    "                                       \"專家C\":decode_unicode(re.findall(\"text\\\"\\:\\s\\\"(.*)\\\"\", str(experts[\"特別收錄\"][\"專家C\"]))[0])},\n",
    "                           \"行銷語分數\":{\"專家A\":BS_score(\"行銷語\")[0],\n",
    "                                       \"專家B\":BS_score(\"行銷語\")[1],\n",
    "                                       \"專家C\":BS_score(\"行銷語\")[2]},\n",
    "                           \"內容摘要分數\":{\"專家A\":BS_score(\"內容摘要\")[0],\n",
    "                                       \"專家B\":BS_score(\"內容摘要\")[1],\n",
    "                                       \"專家C\":BS_score(\"內容摘要\")[2]},\n",
    "                           \"本書特色分數\":{\"專家A\":BS_score(\"本書特色\")[0],\n",
    "                                       \"專家B\":BS_score(\"本書特色\")[1],\n",
    "                                       \"專家C\":BS_score(\"本書特色\")[2]},\n",
    "                           \"名人推薦分數\":{\"專家A\":BS_score(\"名人推薦\")[0],\n",
    "                                       \"專家B\":BS_score(\"名人推薦\")[1],\n",
    "                                       \"專家C\":BS_score(\"名人推薦\")[2]},\n",
    "                           \"特別收錄分數\":{\"專家A\":BS_score(\"特別收錄\")[0],\n",
    "                                       \"專家B\":BS_score(\"特別收錄\")[1],\n",
    "                                       \"專家C\":BS_score(\"特別收錄\")[2]},\n",
    "                           \"最終文案\":final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cdd6d72-3866-4380-955e-a4f31dcbe8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_copies.to_excel(\"book_copy.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
